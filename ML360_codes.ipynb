{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d81c149",
   "metadata": {},
   "source": [
    "## Custom Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c0697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "class Preprocessing(BaseEstimator, TransformerMixin):\n",
    "#     # Class Constructor \n",
    "#     def __init__(self, feature_names):\n",
    "#         self._feature_names = feature_names \n",
    "    \n",
    "    # Return self nothing else to do here    \n",
    "    def fit(self, X, y=None):    \n",
    "        return self \n",
    "    \n",
    "    # Method that describes what we need this transformer to do\n",
    "    def transform(self, X, y=None):\n",
    "        global text_col,user_input\n",
    "        replacement_chars_list = ['~', '`', '!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '()', '-', '--', '_', '__', '=', '+', '[', ']', '[]', '{', '}', '{}', '\\\\', '|', ';', ':', \"'\", '\"', ',', '<', '.', '>', '/', '?', '', ' ', 'na', 'na.', 'n.a.', 'NA', 'NA.', 'N.A.']\n",
    "        user_input=['fully','@@','JARDIM DA PENHA']\n",
    "        for i in user_input:\n",
    "            replacement_chars_list.append(i)\n",
    "        X.replace(replacement_chars_list,  np.nan, inplace = True)\n",
    "       \n",
    "       \n",
    "        \n",
    "        # dropping datetime & timedelta[ns] variables from the data\n",
    "        #X.drop([col for col in X.columns if user_columns_dtypes[col] in ['datetime64', 'datetime64[ns]', 'timedelta64[ns]']], axis = 1, inplace = True)\n",
    "        X=X.apply(lambda col: pd.to_datetime(col, errors='ignore')if col.dtypes == object  else col,  axis=0)\n",
    "        date_columns=X.select_dtypes(include=['datetime64[ns, UTC]','datetime64', 'datetime64[ns]', 'timedelta64[ns]'])\n",
    "        date_col_remove_form_data=list(date_columns.columns)\n",
    "        X.drop(columns=date_col_remove_form_data,inplace=True)\n",
    "        date_columns=date_columns.apply(lambda x : pd.to_datetime(x).dt.date)\n",
    "        date_columns=date_columns.astype('datetime64')\n",
    "        \n",
    "        for i in date_col_remove_form_data:\n",
    "            date_columns[i+'_year']=date_columns[i].dt.year\n",
    "            date_columns[i+'_month']=date_columns[i].dt.month\n",
    "            date_columns[i+'_day']=date_columns[i].dt.day\n",
    "            \n",
    "        date_columns.drop(columns=date_col_remove_form_data,inplace=True)                                         \n",
    "        for col in X.columns:        \n",
    "            pandas_dtype = X[col].dtype\n",
    "            user_datatypes = user_columns_dtypes\n",
    "            user_dtype = user_datatypes[col]\n",
    "        \n",
    "            if (pandas_dtype in ['int', 'int_', 'int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', 'uint32', 'uint64', 'float', 'float_', 'float16', 'float32', 'float64'] and user_dtype == 'object'): # converting int or float to object\n",
    "                X[col] = X[col].astype(object)\n",
    "            elif (pandas_dtype == 'object' and user_dtype == 'int'): # converting object to int\n",
    "                X[col] = X[col].astype(float).astype('int64')\n",
    "            elif (pandas_dtype == 'object' and user_dtype == 'float'): # converting object to float\n",
    "                X[col] = X[col].astype(float)\n",
    "            elif (pandas_dtype in ['int', 'int_', 'int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', 'uint32'] and user_dtype == 'float'): # converting int to float\n",
    "                X[col] = X[col].astype(float)\n",
    "            elif (pandas_dtype in ['float', 'float_', 'float16', 'float32', 'float64'] and user_dtype == 'int'): # converting float to int\n",
    "#                 X[col] = X[col].astype('int64')\n",
    "                if X[col].isnull().sum()==0:\n",
    "                    X[col] = X[col].astype('int64')\n",
    "            elif (pandas_dtype in ['bool', 'bool_'] and user_dtype == 'object'):\n",
    "                X[col] = X[col].astype(object) # converting boolean to object\n",
    "                \n",
    "        ## -----------------------------text column processing code------------------------------------        \n",
    "        \n",
    "        \n",
    "        #global text_col,user_input\n",
    "        user_input=['fully','@@','JARDIM DA PENHA']\n",
    "        stopwords = nltk.corpus.stopwords.words('english')\n",
    "        for i in user_input:\n",
    "            stopwords.append(i)\n",
    "\n",
    "        text_col=[]\n",
    "        try:\n",
    "            for i in X.columns.to_list():\n",
    "                if (X[i].dtype == 'object') and (len(X[i].apply(word_tokenize)[0]) > 3):\n",
    "                    text_col.append(i)\n",
    "            print(text_col)\n",
    "            \n",
    "        except TypeError:\n",
    "            \n",
    "            print('expected string or bytes-like object in dataframe columns')\n",
    "        text_data_columns=X[text_col]\n",
    "        #print(X[text_col])\n",
    "        X.drop(columns=text_col,inplace=True)\n",
    "        ##NLP---------------------------------------------------\n",
    "        text_data_columns.replace('[^A-Za-z\\s]+', '')\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        try:\n",
    "            for i in text_data_columns.columns.to_list():\n",
    "                text_data_columns[i]=text_data_columns[i].str.lower()\n",
    "                text_data_columns[i]=text_data_columns[i].apply(word_tokenize)\n",
    "                text_data_columns[i]=text_data_columns[i].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "                text_data_columns[i]=text_data_columns[i].apply(lambda x: [lemmatizer.lemmatize(item) for item in x ])\n",
    "                #print(text_data_columns)\n",
    "        except AttributeError:\n",
    "                print('some columns are not string datatype so we cant perform NLP tasks')\n",
    "        X=pd.concat([date_columns,text_data_columns,X],axis=1)\n",
    "        return X  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018cab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing=Preprocessing()\n",
    "output=preprocessing.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243fdaff",
   "metadata": {},
   "source": [
    "## create user_df_dtype_dict dictionary using UI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46bd375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_dtypes(self):\n",
    "    global pandas_columns_dtypes\n",
    "    pandas_columns_dtypes = {}\n",
    "    for col in self.columns:\n",
    "        dtype = self[col].dtype\n",
    "        pandas_columns_dtypes[col] = dtype.name\n",
    "    return pandas_columns_dtypes\n",
    "\n",
    "\n",
    "user_df_dtype_dict=pandas_columns_dtypes.copy()\n",
    "\n",
    "## user input backend -------------\n",
    "user_df_dtype_dict['SalePrice']='float64'\n",
    "user_df_dtype_dict['YearBuilt']='float64'\n",
    "user_df_dtype_dict['YrSold']='float64'\n",
    "user_df_dtype_dict['OverallQual']='float64'\n",
    "\n",
    "\n",
    "def user_defined_dtype(user_df_dtype_dict):\n",
    "    pandas_data= pandas_columns_dtypes.copy()\n",
    "    pandas_data.update(user_df_dtype_dict)\n",
    "    user_meta=pd.DataFrame(data=pandas_data.items(),columns=['feature','dtype'])\n",
    "    user_meta.to_excel('user_meta.xlsx')\n",
    "    return user_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85926b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_defined_dtype(user_df_dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e89099d",
   "metadata": {},
   "source": [
    "## Profiling for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9604a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "def AudoEDA(self):\n",
    "    name =[x for x in globals() if globals()[x] is self][0]\n",
    "    file=name + '_EDA_analysis.html'\n",
    "    profile=ProfileReport(self)\n",
    "    profile.to_file(file)\n",
    "###   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
